{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Loan Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install libraries not installed in Google Colab #\n",
        "# ! pip3 install tensorflow_decision_forests --upgrade"
      ],
      "metadata": {
        "id": "cozdbiJrvLbJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YtZPlEOvGjJG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24a1f72-e434-40db-bafc-e1862824c369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:TF Parameter Server distributed training not available (this is expected for the pre-build release).\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries #\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow_decision_forests as tfdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data Frame #\n",
        "Data = pd.read_csv('/content/train_u6lujuX_CVtuZ9i[1].csv')"
      ],
      "metadata": {
        "id": "YWj_DKbGHchB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data with replacements #\n",
        "Data = Data.fillna(0)\n",
        "Data['Gender'] = Data['Gender'].replace(0, 'Unknown')\n",
        "Data['Dependents'] = Data['Dependents'].replace('3+', '4')\n",
        "Data['Dependents'] = Data['Dependents'].replace(0, '0')\n",
        "Data['Dependents'] = Data['Dependents'].replace(3, '3')\n",
        "Data['Married'] = Data['Married'].replace(0, 'Uknown')\n",
        "Data['Self_Employed'] = Data['Self_Employed'].replace(0, 'Uknown')"
      ],
      "metadata": {
        "id": "PR6qJyTLHlDG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create One-Hot-Encoder for preprocessing #\n",
        "one_hot = OneHotEncoder(handle_unknown='ignore')"
      ],
      "metadata": {
        "id": "UkWfn6ulPzet"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data and target with encoder #\n",
        "Data['Dependents'] = one_hot.fit_transform(Data[['Dependents']]).toarray()[:, 3]\n",
        "Data['Education'] = one_hot.fit_transform(Data[['Education']]).toarray()[:,1]\n",
        "Data['Credit_History'] = one_hot.fit_transform(Data[['Credit_History']]).toarray()[:,1]\n",
        "Data['Married'] = one_hot.fit_transform(Data[['Married']]).toarray()[:,1]\n",
        "Data['Self_Employed'] = one_hot.fit_transform(Data[['Self_Employed']]).toarray()[:,1]\n",
        "Data['Gender'] = one_hot.fit_transform(Data[['Gender']]).toarray()[:,2]\n",
        "Data['Property_Area'] = one_hot.fit_transform(Data[['Property_Area']]).toarray()[:,2]\n",
        "\n",
        "Data['Loan_Status'] = one_hot.fit_transform(Data[['Loan_Status']]).toarray()[:,1]"
      ],
      "metadata": {
        "id": "0hEOqI46QAPw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Loan_ID column as it has no affect on approval rate #\n",
        "Data = Data.drop('Loan_ID', 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLTRXGy3Akx",
        "outputId": "9d871059-4f1a-4c8c-b3fe-a2524026930d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a single data piece and label for fitting #\n",
        "Data = tfdf.keras.pd_dataframe_to_tf_dataset(Data, label='Loan_Status')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2yJyBJezPT-",
        "outputId": "fb0077eb-638a-4440-dfe4-c916a327c7e3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_decision_forests/keras/core.py:2036: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  features_dataframe = dataframe.drop(label, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and fit model #\n",
        "model = tfdf.keras.RandomForestModel()\n",
        "model.fit(x=Data)"
      ],
      "metadata": {
        "id": "2H-egrguDf1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6d483ca-dbd4-4308-b1b3-8226d4e14b86"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use /tmp/tmpgzui0nzq as temporary training directory\n",
            "Starting reading the dataset\n",
            "1/1 [==============================] - ETA: 0s\n",
            "Dataset read in 0:00:11.814688\n",
            "Training model\n",
            "Model trained in 0:00:00.697012\n",
            "Warning:  Tracing the TF graph and reading the dataset took more than 50% of the time to effectively train the model (tracing+dataset reading: 0:00:11.814688, training: 0:00:00.697012). This might indicates that the dataset reading operation e.g. tf.data.Dataset is not well configured. In mose cases, this ratio should be <<10%.\n",
            "Compiling model\n",
            "1/1 [==============================] - 13s 13s/step\n",
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f0fa522e710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f0fa522e710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: AutoGraph could not transform <function simple_ml_inference_op_with_handle at 0x7f0fa522e710> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: could not get source code\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0fa542cc90>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}